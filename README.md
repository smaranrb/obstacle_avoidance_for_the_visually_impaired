# Obstacle Avoidance System for Visually Impaired

## Description

This project focuses on developing an advanced obstacle avoidance system tailored to assist visually impaired individuals in navigating footpaths safely. By leveraging a custom trained YOLOv8 Nano object detection mosel and Google Text To Speech, the system detects various obstacles such as potholes, light poles, vehicles, and roadside stalls, providing auditory alerts to users. The primary objective of the project is to enhance the safety and autonomy of visually impaired individuals by providing them with accurate and timely information about their surroundings. The system's features include object detection, audio feedback, and compatibility with a Raspberry Pi 4B or 5. This project targets a broad audience, including visually impaired individuals, caregivers and organizations dedicated to accessibility and inclusion.

## Dependecncies:

- python v3.8 or higher
    - Installation command: `sudo apt get python3`
- mplayer v1.4 or higher
    - Installation command:  `sudo apt get mplayer`

### Python modules:
- ultralytics 8.2.10 or higher
    - Installation command: `pip install ultralytics`
- gtts 2.5 or higher
    - Installation command:  `pip install gtts`

#### If performed on the command prompt
- microconda/anaconda v4.10.3 or higher

## Repository Structure:

### Directories:
- **dataset:** the directory where all images for training, validation and testing are stored along with their respective annotations

- **runs:** the directory where all trained models with their evaluation results are stored 

### Notebooks:
- **predict_audio-output:** to predict the labels for a given image and generating an audio output

- **train:** to train YOLO object detection models

### YAML Files:
- **data:** contains the details of the dataset and generated by roboflow
- **dataset:** contains paths to the images for training and validation, the class names and other details of the dataset 
- **dataset_test:** contains paths to the images for testing the class names and other details of the dataset 

### Other Files:
- **yolov8_weights_custom.pt:** best suited model for object detection in this problem statement
- **clearml.conf:** configuration file to access the ClearML online toolkit
- **test_unseen.sh** shell script to test a model against unseen data
- **README.dataset.txt:** readme file fot eh dataset (auto-generated by roboflow) 

## Training models:

To train any YOLO model:
1. Load your dataset onto the datasets folder
    > **Note:** Dataset should contrain the images and annotations for training, valiation and testing
2. Create/Edit the `dataset.yaml` file according to the directory structure (explained more in `train.ipynb`)
2. Follow the rest of the cells in `train.ipynb`

## Testing models:

To test any YOLO model:
1. Change the path of the testing images in `dataset_test.yaml` by changing the `val` field to the desired directory name (and the `path` field if necessary)
2. Change the path of the model weights (.pt) in the shell file `test_unseen.sh`
3. If you have setup a virtual environment where all dependencies are loaded, activate the corresponding virtual environment.
4. Change the execute permissions of `test_unseen.sh`
    - `chmod +744 ./test_unseen.sh`
5. Execute the shell file
    - `./test_unseen.sh`

> **Note:** For this project, the unseen test images are loacted in the directory `datasets/custom_split/test_unseen` 